{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSOFNkcu7FId"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fertilityRate</th>\n",
       "      <th>lifeExpectancy</th>\n",
       "      <th>mortalityRate</th>\n",
       "      <th>popGrowth</th>\n",
       "      <th>ruralPopPct</th>\n",
       "      <th>gdpGrowthPct</th>\n",
       "      <th>gdpUS</th>\n",
       "      <th>gdpPerCapitaUS</th>\n",
       "      <th>gni</th>\n",
       "      <th>gniPerCapita</th>\n",
       "      <th>pop14under</th>\n",
       "      <th>pop15to24</th>\n",
       "      <th>pop25to64</th>\n",
       "      <th>pop65over</th>\n",
       "      <th>totalPop</th>\n",
       "      <th>happinessScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">Australia</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.814</td>\n",
       "      <td>82.40000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.43922</td>\n",
       "      <td>14.299</td>\n",
       "      <td>2.35114</td>\n",
       "      <td>1.349034e+12</td>\n",
       "      <td>56644.03396</td>\n",
       "      <td>1.587954e+12</td>\n",
       "      <td>60440.0</td>\n",
       "      <td>4520.213</td>\n",
       "      <td>3172.395</td>\n",
       "      <td>12684.814</td>\n",
       "      <td>3555.080</td>\n",
       "      <td>23932.502</td>\n",
       "      <td>7.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>1.752</td>\n",
       "      <td>82.44878</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.56194</td>\n",
       "      <td>14.200</td>\n",
       "      <td>2.82731</td>\n",
       "      <td>1.208039e+12</td>\n",
       "      <td>49937.73139</td>\n",
       "      <td>1.622282e+12</td>\n",
       "      <td>54180.0</td>\n",
       "      <td>4598.344</td>\n",
       "      <td>3155.240</td>\n",
       "      <td>12835.482</td>\n",
       "      <td>3673.646</td>\n",
       "      <td>24262.712</td>\n",
       "      <td>7.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>1.765</td>\n",
       "      <td>82.49756</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.68452</td>\n",
       "      <td>14.096</td>\n",
       "      <td>1.95758</td>\n",
       "      <td>1.323421e+12</td>\n",
       "      <td>53793.53726</td>\n",
       "      <td>1.707621e+12</td>\n",
       "      <td>51360.0</td>\n",
       "      <td>4687.067</td>\n",
       "      <td>3135.675</td>\n",
       "      <td>12974.858</td>\n",
       "      <td>3787.020</td>\n",
       "      <td>24584.620</td>\n",
       "      <td>7.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">Austria</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.490</td>\n",
       "      <td>81.19024</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.12099</td>\n",
       "      <td>42.285</td>\n",
       "      <td>1.14298</td>\n",
       "      <td>3.818057e+11</td>\n",
       "      <td>44176.67174</td>\n",
       "      <td>3.408691e+11</td>\n",
       "      <td>47490.0</td>\n",
       "      <td>1225.425</td>\n",
       "      <td>1008.434</td>\n",
       "      <td>4809.700</td>\n",
       "      <td>1635.101</td>\n",
       "      <td>8678.660</td>\n",
       "      <td>7.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>1.530</td>\n",
       "      <td>81.64146</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.08140</td>\n",
       "      <td>42.095</td>\n",
       "      <td>2.03957</td>\n",
       "      <td>3.940528e+11</td>\n",
       "      <td>45103.32981</td>\n",
       "      <td>3.558314e+11</td>\n",
       "      <td>46130.0</td>\n",
       "      <td>1239.550</td>\n",
       "      <td>1001.790</td>\n",
       "      <td>4851.921</td>\n",
       "      <td>1654.040</td>\n",
       "      <td>8747.301</td>\n",
       "      <td>7.119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fertilityRate  lifeExpectancy  mortalityRate  popGrowth  \\\n",
       "Country   Year                                                            \n",
       "Australia 2015          1.814        82.40000            3.2    1.43922   \n",
       "          2016          1.752        82.44878            3.1    1.56194   \n",
       "          2017          1.765        82.49756            3.0    1.68452   \n",
       "Austria   2015          1.490        81.19024            3.0    1.12099   \n",
       "          2016          1.530        81.64146            3.0    1.08140   \n",
       "\n",
       "                ruralPopPct  gdpGrowthPct         gdpUS  gdpPerCapitaUS  \\\n",
       "Country   Year                                                            \n",
       "Australia 2015       14.299       2.35114  1.349034e+12     56644.03396   \n",
       "          2016       14.200       2.82731  1.208039e+12     49937.73139   \n",
       "          2017       14.096       1.95758  1.323421e+12     53793.53726   \n",
       "Austria   2015       42.285       1.14298  3.818057e+11     44176.67174   \n",
       "          2016       42.095       2.03957  3.940528e+11     45103.32981   \n",
       "\n",
       "                         gni  gniPerCapita  pop14under  pop15to24  pop25to64  \\\n",
       "Country   Year                                                                 \n",
       "Australia 2015  1.587954e+12       60440.0    4520.213   3172.395  12684.814   \n",
       "          2016  1.622282e+12       54180.0    4598.344   3155.240  12835.482   \n",
       "          2017  1.707621e+12       51360.0    4687.067   3135.675  12974.858   \n",
       "Austria   2015  3.408691e+11       47490.0    1225.425   1008.434   4809.700   \n",
       "          2016  3.558314e+11       46130.0    1239.550   1001.790   4851.921   \n",
       "\n",
       "                pop65over   totalPop  happinessScore  \n",
       "Country   Year                                        \n",
       "Australia 2015   3555.080  23932.502           7.284  \n",
       "          2016   3673.646  24262.712           7.313  \n",
       "          2017   3787.020  24584.620           7.284  \n",
       "Austria   2015   1635.101   8678.660           7.200  \n",
       "          2016   1654.040   8747.301           7.119  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_unesco = pd.read_csv(\"unesco.csv\")\n",
    "df_unesco_train = pd.read_csv(\"unesco_train.csv\")\n",
    "df_unesco.set_index([\"Country\", \"Year\"], inplace=True)\n",
    "df_unesco_train.set_index([\"Country\", \"Year\"], inplace=True)\n",
    "\n",
    "df_unesco_train = df_unesco_train[df_unesco_train[\"pop14under\"] > 0]\n",
    "df_unesco_train = df_unesco_train.dropna()\n",
    "df_unesco_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to find the type of machine learning regressor that works the best on our data.  I test this by comparing RMSE's of different learners, including all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "bkcuEkhbGDzM",
    "outputId": "29b9aa77-c6f5-429a-eb80-e9060c496b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear Regression      0.908054\n",
       "K Nearest Neighbors    0.633200\n",
       "Decision Tree          0.721476\n",
       "Random Forest          0.587615\n",
       "Gradient Boosting      0.634489\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Xtrain = df_unesco_train.drop(\"happinessScore\", axis=1)\n",
    "ytrain = df_unesco_train[\"happinessScore\"]\n",
    "\n",
    "def tryModel(model):\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "      StandardScaler(),\n",
    "      model\n",
    "    )\n",
    "\n",
    "    cv_errs = -cross_val_score(pipeline, X=Xtrain, y=ytrain,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
    "  \n",
    "    return pipeline, np.sqrt(cv_errs.mean())\n",
    "\n",
    "lr = LinearRegression()\n",
    "knn = KNeighborsRegressor()\n",
    "dt = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor(n_estimators=100, max_features=\"sqrt\")\n",
    "params = {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}\n",
    "gr = GradientBoostingRegressor(**params) \n",
    "\n",
    "model_dict = {'Linear Regression': lr, 'K Nearest Neighbors': knn, \n",
    "              'Decision Tree': dt, 'Random Forest': rf, 'Gradient Boosting': gr}\n",
    "\n",
    "errs = pd.Series()\n",
    "for k, v in model_dict.items():\n",
    "  errs[k] = tryModel(v)[1]\n",
    "errs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the lowest estimated test RMSE around .59, random forrest is the best machine learning model out of those I tested.  The RMSE of .6 can be interpreted as follows: given a country and a year, a prediction for the happiness score will be off by .6 on average.\n",
    "\n",
    "The cells below is where I perform feature selection, choosing only the features that help to predict happiness scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSkr3GZV3wTb"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=\"sqrt\")\n",
    "# no need to scale for random forest\n",
    "\n",
    "importances = [0 for i in range(len(Xtrain.columns))]\n",
    "\n",
    "iterations = 1000\n",
    "for i in range(iterations):\n",
    "    rf.fit(Xtrain, ytrain)\n",
    "    importances += rf.feature_importances_\n",
    "\n",
    "importances = importances / iterations\n",
    "print(len(importances))\n",
    "print(len(Xtrain.columns))\n",
    "importances = pd.DataFrame({'Feature':Xtrain.columns,'Importance':importances})\n",
    "importances.sort_values(by='Importance').set_index('Feature').plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important = importances[importances[\"Importance\"] > .025]\n",
    "best_features = list(most_important[\"Feature\"])\n",
    "best_features.append('happinessScore')\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These feature importance scores match my intuition.  It makes sense to me that features like GNI Per Capita, life expectancy, and mortiality rate are more important than features like gdp growth and gdp.\n",
    "\n",
    "In the cell below, I'm going to compare and contrast the model with all of the features to one with only the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = pd.Series()\n",
    "\n",
    "Xtrain_best = df_unesco_train[best_features]\n",
    "Xtrain_best = Xtrain_best.dropna()\n",
    "ytrain_best = Xtrain_best[\"happinessScore\"]\n",
    "Xtrain_best.drop(\"happinessScore\", axis=1, inplace=True)\n",
    "\n",
    "def tryModel(Xtrain, ytrain):\n",
    "    cv_errs = -cross_val_score(rf, X=Xtrain, y=ytrain,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "  \n",
    "    return np.sqrt(cv_errs.mean())\n",
    "\n",
    "iterations = 10\n",
    "all_rmse = 0\n",
    "best_rmse = 0\n",
    "\n",
    "for i in range(iterations):\n",
    "    all_rmse += tryModel(Xtrain, ytrain)\n",
    "    best_rmse += tryModel(Xtrain_best, ytrain_best)\n",
    "   \n",
    "errs['All features'] = all_rmse/iterations\n",
    "errs['Best features'] = best_rmse/iterations\n",
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 30\n",
    "errs = {}\n",
    "for i in range(iterations):\n",
    "    rmses = []\n",
    "    rmses.append(tryModel(Xtrain, ytrain))\n",
    "    rmses.append(tryModel(Xtrain_best, ytrain_best))\n",
    "    errs[i] = rmses\n",
    "   \n",
    "\n",
    "errs = pd.DataFrame(errs)\n",
    "errs = errs.rename({0: \"All features\", 1: \"Best features\"})\n",
    "errs = errs.transpose()\n",
    "errs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-hoc pairwise test with bonferroni multiple test correction to test is there is a statistically significant difference between the model with all features and the model with the \"best\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All features</th>\n",
       "      <th>Best features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>All features</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.027928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Best features</td>\n",
       "      <td>0.027928</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               All features  Best features\n",
       "All features      -1.000000       0.027928\n",
       "Best features      0.027928      -1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features     0.603435\n",
      "Best features    0.612214\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "\n",
    "a = sp.posthoc_ttest(errs.transpose().values, p_adjust = 'bonferroni')\n",
    "d = pd.DataFrame(a, columns=errs.columns,index=errs.columns)\n",
    "display(d)\n",
    "print(errs.mean().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large p-value (> alpha = .05) indicates that there is no statstically significant different between the two models.  Because of this, I'm going to use the model with less features for the sake of simplicity.  Finally, I'm going to remove variables that are highly correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fertilityRate',\n",
       " 'lifeExpectancy',\n",
       " 'mortalityRate',\n",
       " 'popGrowth',\n",
       " 'ruralPopPct',\n",
       " 'gdpUS',\n",
       " 'gdpPerCapitaUS',\n",
       " 'gniPerCapita',\n",
       " 'happinessScore']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_no_labels = best_features.copy()\n",
    "best_features_no_labels.remove(\"happinessScore\")\n",
    "print(\"Final features:\")\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df = df_unesco.copy()\n",
    "df = df[df[\"fertilityRate\"] > 0]\n",
    "df = df[df[\"lifeExpectancy\"] > 0]\n",
    "df = df[df[\"mortalityRate\"] > 0]\n",
    "df = df[df[\"popGrowth\"] > 0]\n",
    "df = df[df[\"ruralPopPct\"] > 0]\n",
    "df = df[df[\"gni\"] > 0]\n",
    "df = df[df[\"gdpPerCapitaUS\"] > 0]\n",
    "df = df[df[\"totalPop\"] > 0]\n",
    "\n",
    "# try to fill missing values as best as possible\n",
    "for i, row in df_unesco.iterrows():\n",
    "    if row[\"gdpPerCapitaUS\"] <= 0:\n",
    "        df_unesco.at[i, \"gdpPerCapitaUS\"] = row[\"gdpUS\"]/row[\"totalPop\"]\n",
    "    if row[\"gniPerCapita\"] <= 0:\n",
    "        df_unesco.at[i, \"gniPerCapita\"] = row[\"gni\"]/row[\"totalPop\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final estimated test rmse:  0.5992141461486289\n"
     ]
    }
   ],
   "source": [
    "Xtrain_final = df_unesco_train[best_features]\n",
    "Xtrain_final = Xtrain_final.dropna()\n",
    "ytrain_final = Xtrain_final[\"happinessScore\"]\n",
    "Xtrain_final.drop(\"happinessScore\", axis=1, inplace=True)\n",
    "\n",
    "Xtest = df[best_features_no_labels]\n",
    "Xtest = Xtest.dropna()\n",
    "rf = RandomForestRegressor(max_features=\"sqrt\")\n",
    "rf.fit(Xtrain_final, ytrain_final)\n",
    "\n",
    "def tryModel():\n",
    "    cv_errs = -cross_val_score(rf, X=Xtrain_final, y=ytrain_final,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    return np.sqrt(cv_errs.mean())\n",
    "\n",
    "print(\"Final estimated test rmse: \", tryModel())\n",
    "\n",
    "ytest = rf.predict(Xtest)\n",
    "Xtest[\"happinessScore\"] = ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.to_csv(\"unesco_with_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "466_week2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
